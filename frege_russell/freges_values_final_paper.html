<h1 id="freges-values">Frege’s Values</h1>
<p>In the 1890s Gottlob Frege expanded the power and scope of logic. His stated goal was to show that the natural numbers could be created inside logic. But why was he doing this? What benefits did he think this would have and what value statements did he provide? I will show that what Frege valued was the rigorous pursuit of mathematical truth, and that he viewed his own contributions as entirely methodological. I will further show that this view, that logic serves the broader mathematical endeavor, is consistent with major streams of foundational mathematical activity today. I will examine type theory and the communities who use it to cultivate a flourishing community of mathematical practice. But lurking inside this rosy picture is a new crisis for mathematics. Ironically, this is not another instance of the crises of the 19th and 20th centuries, where mathematics required a renewed commitment to rigor in order to avoid confusion, paradoxes, or errors. There are indeed vocal elements today who claim that we are in just such a crisis! But this time we have all the tools we need to achieve the desired standards. Unfortunately, the proponents of those very tools have themselves brought about a crisis of values, by inviting and supporting nihilistic agents from completely unaligned fields to mine mathematics for commercial gain, while willfully degrading another field of human activity. What we need now is a new commitment to Frege’s values: that rigor is a tool of mathematics, not a value unto itself.</p>
<h2 id="freges-values-1">Frege’s values</h2>
<h3 id="logic-in-service-of-mainstream-mathematics">Logic in service of mainstream mathematics</h3>
<p>Frege’s first big document, the <em>Begriffsschrift</em>, begins its preface with the sentence “The recognition of a scientific truth generally passes through several stages of certainty.”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The rest of the document, and indeed Frege’s entire body of work, is devoted to upgrading the <em>certainty</em> of <em>scientific truth</em>. He is interested in methodology. He does not level any criticisms at the agenda of mathematics or science generally. It’s true that he argues for what we would call a positivist take on science and mathematics, i.e. the position that mathematical objects are real objects in a real abstract and platonic realm of ideas. It’s also true that he argues against a psychological frame for such objects. But the arc of scientific inquiry, and of mathematical research, is a fixed background object that he seems to approve of and wants to enhance. TODO: describe analysis and physics and such, as an example of worthy activity.</p>
<p>The enhancement he wants to offer is epistemological: more airtight arguments, more grounded in logic. This work has two parts. First he will add constructions to logic itself, notably universal quantifiers and a primitive system of types, so that it can express a broader class of ideas. He even includes a roadmap of future goals for logic, to support even more scientific areas such as geometry, analysis, and physics.</p>
<p>With his suite of logical tools, Frege can offer his second idea, which is the Begriffsschrift, or concept script, itself. This is a notational tool for a mathematician to apply the laws of logic to some starting expressions that have been suitably encoded, working down the page applying laws of inference from the small permitted library, until a conclusion is reached. It is crucial that the concept script is a new notation, with little in common with spoken and written human languages except the use of letters for variables (he cites “the inadequacy of language”). Here is an example that in modern notation would be “B ∧ (B → A) → A” or in words “if B holds, and B implies A, then A holds”:</p>
<figure>
<img src="modus_ponens.png" alt="Modus ponens in the concept script" /><figcaption aria-hidden="true">Modus ponens in the concept script</figcaption>
</figure>
<p>and here is his diagram showing that his expressions can subsume the “square of opposition”, a sort of ad-hoc logical tool used over the preceding centuries<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<figure>
<img src="opposition_square.png" alt="Square of opposition" /><figcaption aria-hidden="true">Square of opposition</figcaption>
</figure>
<p>He wants the concept script and logical framework to be adopted. The sales pitch has words like “firm” and “free of gaps”:</p>
<blockquote>
<p>The firmest proof is obviously the purely logical, which, prescinding from the particularity of things, is based solely on the laws on which all knowledge rests.</p>
</blockquote>
<blockquote>
<p>So that nothing intuitive could intrude here unnoticed, everything had to depend on the chain of inference being free of gaps.</p>
</blockquote>
<p>His comparison of the concept script to a microscope is very fruitful. First of all, it is a tool which we use for the purpose of examining the true subject matter at hand, namely scientific truth. But it is “useless for all others” (purposes, that is). It is a scientific instrument and like all scientific instruments it has two natures. First, it is itself a product of science and worthy of study and refinement by scientists (or engineers). But secondly it empowers scientists to use it to make more powerful observations and extend the domain of science.</p>
<blockquote>
<p>Everything that is necessary for a valid inference is fully expressed; but what is not necessary is mostly not even indicated; <em>nothing is left to guessing</em>.</p>
</blockquote>
<p>I will be less interested in the application for which Frege applied his new tools, but let me briefly describe it. Frege wanted to define the natural numbers (positive whole numbers) and the laws of arithmetic entirely inside logic. This would upgrade numbers with more certainty and Kantian analyticicty. It would also dovetail with other work going on in the field, as there was a mathematical community contemporaneous with Frege, and of which he was very aware, who were working diligently to re-define the real numbers to avoid some confusion that had come about in the field of analysis and calculus. The real numbers are built on the rational numbers, which are built on the integers, which are in turn built on the natural numbers. But the natural numbers did not have a satisfactory mathematical definition:</p>
<blockquote>
<p>Yet is it not shameful that a science should be so unclear about its most prominent object, which is apparently so simple?</p>
</blockquote>
<p>He spends many pages trying to define concepts and objects, so that numbers can then be real objects in a platonic realm. He captures his definition using something similar to set theory, which for him takes the form of extensions of propositional functions, meaning all the objects that yield the value True when plugged into a function that takes objects as input and emits either True or False. Once he has 0 and 1 and a successor function, he uses the concept script to prove theorems about arithmetic.</p>
<p>The parts of this overall project that I want to highlight then are these:</p>
<ol type="1">
<li>Science and mathematics have value.</li>
<li>They generate value in part because they are rigorous.</li>
<li>Enhancing the rigor would enhance the power and the value of these activities.</li>
<li>The enhancement can be brought about by expanding logic and by creating methods to effectively wield the logic: tools for people to perform gap-free inference.</li>
</ol>
<p>Goals 1-3 were widely shared by late-19th century mathematicians, kindred spirits such as Richard Dedekind, who were working to provide a sharper and more careful set of definitions of real numbers, continuity, functions and so on. But what Frege wanted were much sharper and stronger tools, placing him outside the mainstream. Frege wanted to focus on the piece we call logic, and make it an explicit partner of mathematics, able to express the mathematical objects, and the mathematical arguments. Compare the concept script notation above with, say, the heavy use of prose in most mathematics textbooks from the last 150 years. Most mathematicians are content with a lesser version of rigor, where arguments are made very carefully and as airtight as possible, but remain optimistically rooted in the intuition and incisiveness of the human operator. Frege did not think this was good enough:</p>
<blockquote>
<p>The requirements on the rigour of proofs inevitably result in greater length. Anyone who does not bear this in mind will indeed be surprised at how long-winded the proof often is here of a proposition that he believes can be immediately grasped in a single act of understanding. This will be particularly striking if we compare Dedekind’s work <em>Was sind und was sollen die Zahlen?</em>, the most thorough work on the foundation of arithmetic that has come to my attention in the last few years. In much less space it pursues the laws of arithmetic much further than is done here. This brevity is admittedly only achieved by not really proving much at all.</p>
</blockquote>
<p>Patrick Massot, a prominent member of the Lean and mathlib community, makes a convincing case<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> that it is easy to overlook special cases such as the empty set when reasoning informally, but that Frege-style gap-free reasoning that is literally being performed today with the help of computers, will catch these cases. This is helpful, even crucial, and Frege deserves credit for focusing on this part of the challenge. Frege was able to relate to the feeling Massot is describing, where the formal system informs the operator that they must consider the case of the empty set:</p>
<blockquote>
<p>one must write down all intermediate steps, to let the full light of consciousness fall upon them.</p>
</blockquote>
<p>I’ll have more to say about computers and mathlib shortly. But before I leave the subject of computers for now, it’s important to note something we do <em>not</em> see in Frege’s value system. There is a danger of conflating stricly computational activity, such as that performed by digital computers, or human computers, with mindless or degrading or even harmful jobs<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. There is no evidence that Frege felt this way about a would-be operator of the concept script. We have just seen that he admitted the proofs would be long, but nowhere does he mention automation or machinery. He seems to have envisioned even the fully rigorous process as intended not only for people, but for mathematicians themselves.</p>
<h2 id="freges-project">Frege’s project</h2>
<h3 id="the-begriffsschrift-and-the-analyticity-of-numbers">The <em>Begriffsschrift</em> and the analyticity of numbers</h3>
<p>The microscope that Frege invented is a fragment of logic with a primitive notion of types. The type system consisted of “objects” at the lowest level, then functions of objects at level 1, then higher functions at the higher levels (e.g. a function of two arguments that takes a second-level function and an object would be a third-order function). His logical rules of inference are these nine (in modern notation):</p>
<pre><code>⊢ a → (b → a)
⊢ (c → (b → a)) → (c → b) → (c → a)
⊢ (d → (b → a)) → b → (d → a)
⊢ (b → a) → (¬a → ¬b)
⊢ ¬¬a → a
⊢ a → ¬¬a
⊢ (c ≣ d) → f(c) → f(d)
⊢ c ≣ c
⊢ ∀a.f(a) → f(c)</code></pre>
<p>His introduction of the universal quantifier (∀ in modern notation) was original. He was careful about the use of bound and free variables, and of the fact that the quantifieres need to have their scope specified. He also distinguished two kinds of equality to accompany his two levels of meaning, known as <em>sense</em> and <em>reference</em>. The sense of an expression is the exact meaning of the syntactic encoding, and the reference is a semantic object to which the sense eventually refers, possibly after doing a lot of work to unpack the syntax. His famous linguistic example is how “the morning star” has the same reference as “the evening star” since both are the planet Venus. But they differ at the level of sense, and they pick out the planet via different methods. Similarly, the equation “a = a” holds because the senses are syntactically the same, whereas “a + b = b + a” holds after a short proof, i.e. the senses differ but the references turn out to be the same.</p>
<h2 id="disagreement-with-hilbert">Disagreement with Hilbert</h2>
<h3 id="frege-doesnt-notice-the-synergy">Frege doesn’t notice the synergy</h3>
<p>In 1899 Hilbert published <em>Foundations of Geometry</em>, which we recognize now as a major development. He proposed splitting mathematical theories, such as Euclidean geometry, into two parts. One part contains the axioms of the theory, including any conceptual objects which the theory will talk about and operate on. For geometry the objects are <em>points</em>, <em>lines</em>, <em>line segments</em>, <em>circles</em>, <em>angles</em>, and so on. The axioms would include Euclid’s postulates, namely (from Wolfram MathWorld<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>):</p>
<ol type="1">
<li>A straight line segment can be drawn joining any two points.</li>
<li>Any straight line segment can be extended indefinitely in a straight line.</li>
<li>Given any straight line segment, a circle can be drawn having the segment as radius and one endpoint as center.</li>
<li>All right angles are congruent.</li>
<li>Given any straight line and a point not on it, there exists one and only one straight line which passes” through that point and never intersects the first line, no matter how far they are extended.</li>
</ol>
<p>The second part of the theory is to take the axioms and <em>interpret</em> them in some specific mathematical setting. We could interpret all the objects in the usual Euclidean way in the plane, for example. But we could also work on a two-dimensional sphere and interpret “point” to mean “pair of antipodal points on the sphere” and “line” to mean “great circle”. We then get a second consistent theory except for postulate 5, which fails to hold because instead of there existing one such line, there are none!</p>
<p>There are at least three things going on here! First of all, it condenses geometry, both Euclidean and non-Euclidean, into a concise logical package. Secondly it empowers us to split our arguments into two parts. One part can focus on all the deductions we can make simply based on the axioms, without referring to the interpretation. Some results, such as the content of postulate 5, will not be provable that way. We have to pass to the interpretation that lives on the flat plane before we can prove it, and so it’s more contingent, or even <em>synthetic</em> to use Kant’s term. The results that stem strictly from the axioms would then count as <em>analytic</em>. I like to think of these analytic theorems as supplying answers to “why” questions. Why do [TODO: better example]? Because <em>anything</em> that obeys postulates 1-4 also obeys this rule.</p>
<p>But Hilbert’s method also gives us one more capability. We can use it to study the axiom systems themselves and ask questions about the consistency of the axioms, including whether some of the axioms are independent. Since there are two interpretations of 1-4 one of which obeys postulate 5 and one of which does not, we can conclude that postulate 5 does not follow from 1-4. That’s the result that took 2,000 years to discover. By moving back and forth between the axioms and some clever special models, we can conclude things just about the axioms. The independence of axiom 5 follows from an argument that uses a model. This is standard metamathematical stuff these days, which is why this was a major development.</p>
<p>When I learned that Frege responded strongly <em>against</em> this idea of Hilbert’s, I was truly surprised. What were his objections?</p>
<blockquote>
<p>No man can serve two masters. One cannot serve both truth and untruth. If Euclidean geometry is true, then non-Euclidean geometry is false, and if non-Euclidean geometry is true, then Euclidean geometry is false.</p>
</blockquote>
<blockquote>
<p>If one is content to have only phantoms hovering around one, there is no need to take the matter so seriously; but in science we are subject to the necessity of seeking after truth.</p>
</blockquote>
<p>The “phantoms” would presumably be the bare axiom system, devoid of interpretation.</p>
<p>It seems clear Frege is misunderstanding Hilbert, but I think we can learn some important lessons from that. The misunderstanding is that Frege is unable to, or unaware that he should, <em>postpone</em> the interpretation of the axioms. The phantoms are temporary, and the process definitely has two steps. Frege insists in the first quote that the axioms must be <em>true</em> which entails that they also be <em>fully interpreted</em>. He and many other thinkers believed they were being invited to live only in axiom-space, proving empty results with no meaning. This was likened (pejoratively) to a game, and is given the name “formalism”. Hilbert retorted in 1919:</p>
<blockquote>
<p>We are not speaking here of arbitrariness in any sense. Mathematics is not like a game whose tasks are determined by arbitrarily stipulated rules. Rather, it is a conceptual system possessing internal necessity that can only be so and by no means otherwise.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</blockquote>
<p>I would argue that Frege is doing more than simply misunderstanding the proposal. He is defending mathematics from being drained of meaning. A geometrical point is a mathematical object and claims about it can be true or false, and such claims have value. An axiom is just a phantom, and has no value at all. This is very clarifying for us. If we consider Hilbert’s procedure a piece of new technology, Frege is a luddite, worrying whether it will damage the field of mathematics.</p>
<p>Frege must have believed this so fully that he did not take advantage of the synergy with his life’s work. The combination of axioms with logic allows an even larger portion of mathematical proofs to remain analytic, rigorous, and general. The original theorems in planar geometry are fully recovered after performing interpretation, so nothing is lost but many new theorems are gained simultaneously, across all known and future interpretations.</p>
<p>In hindsight, Frege was trying to base his theory of natural numbers directly in Platonic philosophical bedrock. He spent many pages arguing philosophically about concepts, functions, and extensions of functions, to lend credence that numbers are real objects. This is the postivist part of his philosophy, but it’s actually not dependent on, or coupled to, the logical tools. We can preserve the logic and the value system, the quest for mathematical truth, and plug these into Hilbert’s axiomatic approach instead of in positivism. In fact we can even preserve the positivism if we want to bless certain interpretations of the axioms as “real” and others as “fictitious”, but I don’t have much to say about that.</p>
<h2 id="modern-foundations">Modern foundations</h2>
<h3 id="synthesis-of-frege-and-hilbert">Synthesis of Frege and Hilbert</h3>
<p>Here is a very informal picture of modern mathematical foundations such as type theory. Mathematics has a metaphorical graph structure. It’s not a true formal graph, but the metaphor is so close to true that perhaps it could be made precise. Each node is a theorem, and the edges (which are directed edges) represent the interdependency between the theorems. In other words, each node has a proof that makes use of the incoming edges. Maybe there are multiple proofs, each of which draws on a different subset of the edges. The source nodes, those with no incoming edges, are either axioms or definitions. The leaf nodes, with no outgoing edges, are results that are not yet used to prove something else. Some of these are at the frontier of research, and might be extended one day with outgoing edges to new results.</p>
<p>Let’s fix our attention on some node, such as Brouwer’s fixed point theorem<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. Call this node BFPT. Now light up all the nodes that lie on some path that flows <em>into</em> BFPT. If we are working in a foundation system like ZFC, then there are some ZFC axiom nodes many edges away, and also some definition nodes from various theories that we need (set theory and topology maybe). From these there are edges that flow through a bunch of intermediate nodes (lemmas and other theorems) into BFPT. For example, somewhere there is a node that states that the circle is not a retract of the disk. This can all be formalized in a computer program (perhaps a proof assistant) that offers a system of logic together with ZFC. We then have some really valuable outputs: we have BFPT itself, plus some documentation about the proof. But note that it’s <em>relative to</em> a few things: the choice of ZFC as our foundations, the choice of logical system, and the computer software, for example Metamath<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Hopefully the computer program doesn’t add very much on top of ZFC and the logical system, but it’s always possible there are bugs or other caveats hiding in there, so we’d better include it.</p>
<p>This relativism is a part of the modern picture of mathematics that I want to highlight so we can compare it with Frege’s ideas. Mathematicians themselves explore the relativism inside of mathematics, by swapping in various axiom systems and various logical systems, and re-proving the theorems. Some mathematicians practice <em>reverse mathematics</em><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> which is a project to explore the entire graph I described, for example by discovering requirements for an axiom system to support (flow to) some family of theorems. Software practitioners that use multiple computer software paackages in fact <em>must</em> move between foundations, since the implementations cannot be moved easily between programming languages. There is a large body of Coq software, and a newer and quickly growing body of Lean software as well, and similar bodies in each other language.</p>
<p>Frege acknowledged that there may be imperfections in his logical axioms and inference rules. In fact he was made aware of a paradox by Bertrand Russell and tried to repair it. But he doesn’t indicate that we should entertain having more than one such system. It’s nearly certain that his views were incompatible with such a notion. He tried in true positivist fashion to ground his logic in philosophical bedrock, in order to increase the number of true, positivist, complete logics from zero to one. His aversion to Hilbert’s rootless vision of axiom systems is another hint that there was room for only one version of the truth. We can’t rule out that he could have made room for multiple foundational vantage points, of course. Setting that difference aside, the narrative that begins <em>after</em> we select a foundation is very much compatible with Frege: we use the foundation to prove the same family of theorems, for the same scientific reasons, and establish them firmly and free of gaps.</p>
<p>The particular foundation offered by Martin-Löf’s intuitionistic type theory<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a><a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> is especially noteworthy in this context, since it so perfectly incorporates the Hilbert picture into the foundations, while also capturing all three of Frege’s most important contributions that I am highlighting: logic, a system of types, and two kinds of equality. In intuitionistic type theory the types are “Hilbertian”, meaning they are abstract objects that are meant to eventually be interpreted into more concrete mathematical objects. And the interpretation process is completely formal and mathematical! For example if a mathematician has some objects of interest to which they wish to apply type theory (such as sets, or sheaves of sets over a topological space, or many other examples), they simply have to arrange for those objects to live inside a category with a few special properties and the type theory will automatically be interpretable on these objects. Proofs expressed in type theory become proofs about those objects. Different versions of type theory with more or fewer features will require different features to be present in the category. That covers the Hilbert side of things.</p>
<p>On the Frege side, intuitionistic type theory has his notion of function objects and his distinction between free and bound variables, and about variables having types. In type theory the logical framework is actually emergent from the type system! This is in some sense the greatest validation of Frege of all. Just by having function types, product types, and coproduct types, and assigning universal properties to these, we do not need to separately impose a logic. The behavior of the function types automatically establishes that B ∧ (B → A) → A. The behavior of the product types satisfies the need to have conjunction, and the coproduct types do the same for disjunction. Type theorists call this emergent logic “internal” since it uses the material of the types to state and prove results. Whereas Frege’s goal was to absorb the natural numbers, and hence part of mathematics, into logic, the modern perspective is to couple them in the opposite way: logic emerges from mathematics!</p>
<p>Finally we come to Frege’s distinction between “a = a” and “a + b = b + a”. This has been the most recent and perhaps unexpected vindication of Frege’s priorities. Intuitionistic type theory indeed includes exactly the two kinds of equality Frege distinguished. One of them, dubbed “judgmental equality”, operates at the level of sense while the other, named “propositional equality”, which is a <em>type</em>, corresponds to reference. Having equality of sense gives you equality of reference automatically, but not vice versa. The exploration of propositional equality types has led to the discovery of homotopy type theory and its infinite tower of equality types. Since equality is a type, there can be equalities between equalities and so on. This then turns out to generate an even more powerful theory for proving mathematical results. Come to think of it, perhaps this is the most impactful validation of Frege’s vision!</p>
<h2 id="proof-assistants">Proof assistants</h2>
<h3 id="and-their-communities">And their communities</h3>
<p>Frege’s vision was for mathematicians to use logic and gap-free formal methods to strengthen the research they were already doing, i.e. the seeking of scientific truth. Nowhere is this goal more visibly realized than in the community projects that have grown up around specific proof assistants. Two prominent examples are Mathematical Components<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>, which uses the Coq proof assistant, and Mathlib<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> which uses the newer Lean proof assistant. There are mathematical communities around each of the other proof assistants as well, such as Isabelle, HOL Light, Agda, and so on. Each community is growing, and I imagine new languages will come along every few years as well. The mathematical communities are distinct (but overlapping) communities compared to the ones that implement and support the proof assistant software. The goal is to formalize some body of mathematics, eventually all of it, <em>using</em> the proof assistant. The math libraries are therefore a combination of a software project and a mathematical project. It will help to tease out what parts the computer is currently helping with, because then we can spot the area where the crisis has begun.</p>
<p>By way of example I used the Lean proof assistant myself, both to assess the Mathlib library’s support for smooth manifolds and differential geometry and to learn to contribute to the Mathlib project. I ended up proving a proposition that the collection of smooth functions from a fixed smooth manifold M to the real numbers form a real algebra, with multiplication and addition given by the corresponding pointwise operations<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. Lean has a small “trusted kernel” where the core logic is implemented, and this corresponds to Frege’s logic, albeit expanded into the more powerful logic of dependent type theory. In Lean proofs can be built up incrementally with tactics that advance the state of the proof by applying various transformations and lemmas. Sometimes it’s more intuitive to apply a transormation to the chain of steps that started with the assumptions, or sometimes you want to transform the chain that leads to the goal, eventually meeting in the middle and forming an unbroken chain. The software permits you to think of one step as a possibly large sub-problem, which becomes the current lemma to prove. What the computer is doing among other things is to bring focus and a linear ordering to the process. Someone directly using Frege’s concept script would have to organize the flow of information as an extra task on top of the strategic and tactical challenges that the logic itself requires.</p>
<p>In summary, to formalize a proof you must:</p>
<ol type="1">
<li>Formalize all the definitions.</li>
<li>Plan the strategy, i.e. the method of proof. In my case the strategy was to prove that the collection of smooth real-valued functions satisfied each of the half-dozen requirements to be an algebra.</li>
<li>Perform many iterations of the small-scale tactical piece: select a rule or lemma from the library, and apply it somewhere on the frontier of the proof.</li>
<li>Choose an order to perform the actions in 3.</li>
</ol>
<p>The computer helps with 3 and 4, and I want to come back and focus on 3 shortly. The community manages the storage of definitions and existing theorems in the digital library (such as the Mathlib Github repository), which helps with 1. The mathematical content exists mainly in 2. Often an existing known proof is what you need to formalize, but in other situations you might have reason to prove the result with a different method in order to fit the logic being used. For example, some type theories do not offer classical logic such as the law of the excluded middle, requiring constructive proofs. Often these are not available in the literature.</p>
<p>Lean’s tactics engine is one way to implement 4, but other systems like Agda lack this explicitly incremental paradigm (i.e. where you write each step into the source code and it gets saved there for others to see), but offer interactive tools to probe the state of the proof, or leave holds to come back to later, but where the contortions the user went to are not saved with the file.</p>
<p>So what about 3? If you are in the middle of a proof, and you believe that elsewhere in the library is a lemma that the pointwise product of two smooth functions is smooth, how do you find it so that you can type its name? What if you don’t know whether that lemma is available or not? This portion of the task is not apparent in Frege’s description but turns out to dominate the work. This is also the least mathematical part of the process! And it is here where mathematicians began to envision a role for artificial intelligence. What if I was in the middle of this proof and I could ask the proof assistant to <em>search</em> for an appropriate lemma? It could use any combination of brute-force search through all the definitions in the library, or some naming hints, or even some patterns learned from a database of example proofs. Such general-purpose tools are sometimes called “hammers” because of the name of an early example. The community is eager for new hammers to help with such searches. One recent example in Coq was worthy of publication<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. The expertise required is a quite orthogonal to the content of smooth manifolds, and so it makes sense for a different sort of specialist to help tackle it.</p>
<p>But once the AI community became aware of how much progress the formalization community had made, something began to change. Some of the AI researchers and some of the mathematicians started to move away from Frege’s vision, and began to fixate on the computer itself. Here is an analogy. Imagine the songwriter Paul McCartney sitting with his guitar trying to write a new song under a deadline. He decides to strum quickly, moving between a few chords while humming some notes. The sound of his guitar and his own humming come back into his ears and he listens to the proto-music and reacts to it, extending the melodic line and tweaking the chords. After about a minute, he is humming the melody of the song “Get Back” and the act of creativity is complete<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>. In this story, Paul is the mathematician, and mathematics is music. The guitar is the proof assistant. He both plays the guitar, and listens to the guitar. The guitar makes noises he could never make with his own body, but he must operate it. In some sense when you strum the guitar, you don’t know exactly what it will sound like. The guitar lets you know. Now imagine that a journalist observes Paul’s songwriting session and writes an article in the Arts section of a newspaper with the headline “Guitar finally writes music”.</p>
<h2 id="silicon-reckoner">Silicon Reckoner</h2>
<h3 id="grappling-with-what-mathematical-activity-is-in-a-defensive-posture-wrought-by-recent-capitalist-history.">Grappling with what mathematical activity is, in a defensive posture wrought by recent capitalist history.</h3>
<p>In the 2020 Quanta Magazine article “How Close are Computers to Automating Mathematical Reasoning”<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> we get a good status report on where we stand with Frege’s program, for good and ill. Many researchers are quoted in the article, but their viewpoints do not gel into a single coherent narrative. The picture becomes much clearer if you examine each quote and ask “is this person focused on helping <em>people</em> do math, or computers?”</p>
<p>Michael Harris wants to do math and worries the computer makes it harder: “By the time I’ve reframed my question into a form that could fit into this technology, I would have solved the problem myself.”</p>
<p>Kevin Buzzard wants computers to do the math and claims that mainstream mathematians want the same: “Computers have done amazing calculations for us, but they have never solved a hard problem on their own,” he said. “Until they do, mathematicians aren’t going to be buying into this stuff.”</p>
<p>Emily Riehl wants to do math and wants her students to do it too: “It’s not necessarily something you have to use all the time, and will never substitute for scribbling on a piece of paper,” she said, “but using a proof assistant has changed the way I think about writing proofs.”</p>
<p>But Christian Szegedy (at Google) and Josef Urban (at the Czech Institute of Informatics, Robotics and Cybernetics) want to teach computers do both propose and prove theorems:</p>
<blockquote>
<p>Urban was partially inspired by Andrej Karpathy, who a few years ago trained a neural network to generate mathematical-looking nonsense that looked legitimate to nonexperts. Urban didn’t want nonsense, though — he and his group instead designed their own tool to find new proofs after training on millions of theorems. Then they used the network to generate new conjectures and checked the validity of those conjectures using an ATP called E.</p>
<p>The network proposed more than 50,000 new formulas, though tens of thousands were duplicates. “It seems that we are not yet capable of proving the more interesting conjectures,” Urban said.</p>
</blockquote>
<blockquote>
<p>[Szegedy’s] group at Google Research recently described a way to use language models — which often use neural networks — to generate new proofs. After training the model to recognize a kind of treelike structure in theorems that are known to be true, they ran a kind of free-form experiment, simply asking the network to generate and prove a theorem without any further guidance. Of the thousands of generated conjectures, about 13% were both provable and new (meaning they didn’t duplicate other theorems in the database). The experiment, he said, suggests that the neural net could teach itself a kind of understanding of what a proof looks like.</p>
<p>“Neural networks are able to develop an artificial style of intuition,” Szegedy said.</p>
</blockquote>
<p>Timothy Gowers says computers will literall replace mathematicians (without saying whether he thinks this is good):</p>
<blockquote>
<p>mathematicians will enjoy a kind of golden age, “when mathematicians do all the fun parts and computers do all the boring parts. But I think it will last a very short time.”</p>
</blockquote>
<p>Michael Harris has some pushback on this: “Even if computers understand, they don’t understand in a human way.”</p>
<p>Suppose you are a mathematician who finishes reading this article and feels a sense of disgust and dread, as I did. Where is it coming from? I would offer a final consultation with Frege to get to the bottom of it. Frege wanted to derive arithmetic from logic in order to give it the firmest epistemological status of all: <em>analytic truth</em>. Facts that do not require checking any data at all, but simply emerge from the logical bedrock. Frege compares it in the <em>Begriffsschrift</em> to condensation of moisture from the air into visible droplets. It’s not very likely that Frege succeeded in this project, since he had to introduce functions and sets and other ideas in order to eventually state what the natural numbers are. Analytic truths may be entirely too trivial to generate anything of interest to a person, or a mathematician for that matter.</p>
<p>Computers are analytic machines. They contain only logic gates and storage. If we feed a neural network a corpus of photographs paired with English text captions, we can build a tool that lets users type “banana” and see some hallucination of a banana built from… what? Its inputs:</p>
<ol type="1">
<li>Photographs taken by people, paired with captions written by people.</li>
<li>The specification of a neural network input by people.</li>
<li>The specification of a learning objective such as an error rate matching captions to images, input by a person.</li>
</ol>
<p>The output after typing “banana” is determined by these inputs. Every iota of agency is human. None is the computer’s. Szegedy and Urban must fundamentally disagree, since the software they are busy building would be software that takes responsibility for composing new photographs and captions. The analytic engine, that still contains only inputs 1, 2, and 3, would gain respondibility for performing action 1. The misunderstanding is so complete that it can generate horror. Szegedy’s confusion can be traced to a misreading of Frege:</p>
<blockquote>
<p>Mathematics is the discipline of pure reasoning. Mathematical reasoning is not about mathematics per se, it is about reasoning in general.</p>
</blockquote>
<p>This is taken from Szegedy’s 2020 article<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> as cited by Harris<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>, who grapples with this horror in his writing.</p>
<p>I hope that our discussion of Frege’s vision, and of the living embodiment of his vision in the community of formal mathematics, makes this statement appear as wrong as wrong can be. The good news is that it is fully explanatory of why someone would pursue so tautological a project as building a machine to emit theorems and proofs and call it mathematics.</p>
<p>If you worry as I do that mathematics is nowhere to be found in Szegedy’s vision, but that Google may coopt the power to define mathematics as it sees fit and starve traditional mathematical activity of resources, human and capital, then we can start also wondering what to do about it.</p>
<p>Besides proving and re-proving theorems, the activity of formalization has the side effect of digitizing mathematical results and their proofs. The structured files are tautologically machine-readable, and so can be mined for other purposes if posted on the public internet without restricted licenses. Whenever data is being moved from the context in which it was created into a new context, we need to be on the lookout for ethical lapses, both intended and accidental.</p>
<p>Digital mathematical repositories are under investigation by various teams with multiple applications in mind. Here is a survey of a few such projects:</p>
<p><a href="https://formalabstracts.github.io">FAbstracts</a>. This project has a muddled vision statement, including the incompatible goals of “FAbstracts enables machine learning in math”, and “tools for exploration such as a Google Earth for mathematics, providing an intuitive visual map of the entire world of mathematics”.</p>
<p><a href="https://topos.site/blog/2021/07/introducing-the-mathfoldr-project/">Mathfoldr</a>. This project has more humanistic goals: “MathFoldr will provide search and literature curation tools that will make mathematics more accessible, with the ultimate goal of transforming the way mathematics is created and navigated”.</p>
<h2 id="conclusion">Conclusion</h2>
<h3 id="stick-with-frege.-protect-math.">Stick with Frege. Protect math.</h3>
<p>Frege thought he saw phantoms when he was introduced to formalism. What would he make of the images emitted by deep learning networks that are tuned on millions of images and textual captions, then inverted to generate images from text? These networks are just logical systems that digest data and update themselves in a way that minimizes a calculated value. When we type “banana” and examine the resulting image, we face a test. One common response is to marvel that the computer can generate an image of a banana, and to compare the psychedelic patterns of noise to human art. These are the people who see phantoms but believe they are seeing people. The computer cannot generate new material, it is truly an analytic machine and can only permute the human input according to human-programmed rules. They project human intent and human creativity onto the machine, and it’s hard to imagine a more confused and degrading response. This fearful situation is not some cherry-picked analogy. Literally the same engineers who built these tools are looking at mathematical theorems and proofs as another corpus to ingest. They plan to build machines that emit pictures of mathematical bananas, and hope that we keep projecting ourselves onto their work. We are the instruments who will launder their tautologies and call it mathematics.</p>
<p>Humans have always had a complex relationship with our tools. We use them for certain purposes, but we also improve them. Sometimes the tool is at the center, sometimes at the periphery. Tools that have had especially wide-ranging impacts include writing and its sequels: the printing press and the digital computer. In the 21st century the computer has proven especially effective at drawing our attention away from the problems it is solving and directing them inward, into the computer. The field of mathematics has its own parallel narrative of interactions with these technologies. Consider for example the growing turmoil around the mathematical publishing industry. It’s not very unfair to stipulate that there are rapacious commercial entities who mine mathematical writing for profit and adopt exploitative practices entirely divorced from the goals of the community itself. Who see mathematics not as value-laden directly, but who see the value it holds for us and to leverage it, to trade it for money and power, rather than enhance it. I would further stipulate that this sort of antagonistic system is an outgrowth of even more general systems of culture and capital. The logical inference is that we should be constantly assessing our alignment with such entities, to try to preserve what we value. If we value the human activity of generating beautiful mathematical theories with high standards of rigor, as Frege did, then we have a simple test we can perform. We can ask whether the other entity shares that goal or not.</p>
<p>TODO: analytic, as good, but as bad.</p>
<section class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><em>Begriffsschrift</em>, p. 1<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Read more at https://en.wikipedia.org/wiki/Square_of_opposition<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://www.imo.universite-paris-saclay.fr/~pmassot/files/exposition/why_formalize.pdf<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Daston, Lorraine. “Calculation and the Division of Labor, 1750-1950.” Bulletin of the German Historical Institute 62.Spring (2018): 9-30.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>https://mathworld.wolfram.com/ParallelPostulate.html<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>https://en.wikipedia.org/wiki/David_Hilbert#cite_note-44<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Megill, Norman D. and Wheeler, David A. (2019) <em>Metamath: A Computer Language for Mathematical Proofs</em>, Lulu Press. http://us.metamath.org/downloads/metamath.pdf<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Simpson, Stephen G. (2009), <em>Subsystems of second-order arithmetic</em>, Perspectives in Logic (2nd ed.), Cambridge University Press.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Intuitionistic_type_theory<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>https://plato.stanford.edu/entries/type-theory-intuitionistic/<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>https://math-comp.github.io<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>https://leanprover-community.github.io<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>https://github.com/glangmead/geometry/blob/ab8cbeab722eb3df8d77885f812af8063b1f5906/src/algebra_of_smooth_functions.lean<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>Czajka, Ł., Kaliszyk, C. Hammer for Coq: Automation for Dependent Type Theory. J Autom Reasoning 61, 423–453 (2018). https://doi.org/10.1007/s10817-018-9458-4<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>https://www.youtube.com/watch?v=9kOQ5sgzhRA<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>https://www.quantamagazine.org/how-close-are-computers-to-automating-mathematical-reasoning-20200827/<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>Szegedy C. (2020) A Promising Path Towards Autoformalization and General Artificial Intelligence. In: Benzmüller C., Miller B. (eds) Intelligent Computer Mathematics. CICM 2020. Lecture Notes in Computer Science, vol 12236. Springer, Cham. https://doi.org/10.1007/978-3-030-53518-6_1<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>https://siliconreckoner.substack.com/p/intelligent-computer-mathematics<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
