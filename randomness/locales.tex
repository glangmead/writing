\documentclass[14pt]{extarticle}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{tikz-cd}
\usepackage{tipa}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{comment}

%\usepackage{mathptmx}

%\usepackage[osf,slantedGreek]{mathpazo}
%\usepackage{newtxtext}
%\usepackage{newtxmath}
%
% uncomment the four lines below to switch to stix times
%\usepackage{stix} % when using stix, \circ doesn't have binary operator spacing, so fix that
%\let\mycirc\circ
%\renewcommand{\circ}{\mathbin{\mycirc}}
%\newcommand{\bracket}[2]{\left\<#1,#2\right\>}
%\newtheorem{claim}{Claim}


%%% Common categories
\newcommand{\tp}{\;\mathrm{type}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\G}{\Gamma}
\newcommand{\pit}[1]{\prod_{(#1)}} % pi-type
\newcommand{\pitxa}{\pit{x:A}}
\newcommand{\sit}[1]{\sum_{(#1)}} % sigma-type
\newcommand{\ent}{\vdash}
\newcommand{\adj}{\dashv}
\newcommand{\refl}{\ensuremath{\textsf{refl}}}
\newcommand{\ap}{\ensuremath{\textsf{ap}}}
\newcommand{\ind}{\ensuremath{\textsf{ind}}}
\newcommand{\lift}{\ensuremath{\textsf{lift}}}
\newcommand{\inv}{\ensuremath{\textsf{inv}}}
\newcommand{\concat}{\ensuremath{\textsf{concat}}}
\newcommand{\transport}{\ensuremath{\textsf{transport}}}
\renewcommand{\sec}{\ensuremath{\textsf{sec}}}
\newcommand{\retr}{\ensuremath{\textsf{retr}}}
\newcommand{\total}{\ensuremath{\textsf{total}}}
\newcommand{\isequiv}{\ensuremath{\textsf{is\_equiv}}}
\newcommand{\fib}{\ensuremath{\textsf{fib}}}
\newcommand{\id}{\ensuremath{\text{id}}}
\newcommand{\judgeq}{\ensuremath{:\equiv}}
\newcommand{\reflfx}{\ensuremath{\refl_{f(x)}}}

\newcommand{\rr}{\ensuremath{\mathbb{R}}}
\newcommand{\rrn}{\ensuremath{\mathbb{R}^n}}
\newcommand{\rrm}{\ensuremath{\mathbb{R}^m}}
\newcommand{\rrx}{\ensuremath{\mathbb{R}[x]/x^2}}
\newcommand{\rry}{\ensuremath{\mathbb{R}[y]/y^2}}
\newcommand{\cc}{\ensuremath{\mathbb{C}}}
\newcommand{\nn}{\ensuremath{\mathbb{N}}}
\newcommand{\dd}{\ensuremath{\mathbb{D}}}
%\newcommand{\vv}{\ensuremath{\mathbb{V}}}
\newcommand{\cinfty}{\ensuremath{C^{\infty}}}
\newcommand{\smfd}{\textsf{SmoothMfd}}
\newcommand{\calg}{\textsf{CAlg}_{\rr}}
\newcommand{\cart}{\textsf{CartSp}}
\newcommand{\formalcart}{\textsf{FormalCartSp}}
\newcommand{\formalsmoothset}{\textsf{FormalSmoothSet}}
\newcommand{\smoothset}{\textsf{SmoothSet}}
\newcommand{\setcat}{\textsf{Set}}
\newcommand{\psh}[1]{\textsf{Psh}(#1)}
\newcommand{\sh}[1]{\textsf{Sh}(#1)}
\newcommand{\pshcart}{\psh{\cart}}
\newcommand{\rmodal}{\Re}
\newcommand{\imodal}{\Im}
\newcommand{\shape}{\ensuremath{\text{\textesh}}}
\newcommand{\op}[1]{#1^{\textsf{op}}}
\newcommand{\pt}{\mathrm{pt}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\BAut}{\mathrm{BAut}}
\newcommand{\im}{\mathrm{im}}
\newcommand{\Fin}{\mathrm{Fin}}
\newcommand{\Type}{\mathrm{Type}}
\newcommand{\bottom}{\ensuremath{\bot}}
\newcommand{\Frm}{\ensuremath{\mathsf{Frm}}}
\newcommand{\sFrm}{\ensuremath{\mathsf{\sigma Frm}}}
\newcommand{\Locale}{\ensuremath{\mathsf{Loc}}}
\newcommand{\Topcat}{\ensuremath{\mathsf{Top}}}
\newcommand{\slocale}{\ensuremath{\mathsf{\sigma Loc}}}
\newcommand{\opens}[1]{\ensuremath{\mathcal{O}(#1)}}
\renewcommand{\o}{\ensuremath{\mathcal{O}}}

\newcommand{\bg}{\ensuremath{\textbf{B}G}}
\newcommand{\bgconn}{\ensuremath{\textbf{B}G_{\textsf{conn}}}}
\newcommand{\bgdiff}{\ensuremath{\textbf{B}G_{\textsf{diff}}}}
\newcommand{\ran}{\ensuremath{\mathrm{Ran}}}
\newcommand{\sig}{\ensuremath{\sigma-}}

\newcommand{\gc}[1]{\marginpar{\bf $\leftarrow$ {#1}}}
%\newcommand{\gc}[1]{}
\newcommand{\commentout}[1]{}

\newtheorem{mydef}{Definition}
\newtheorem{mythm}{Theorem}
\newtheorem{mylemma}{Lemma}
\newtheorem{myprop}{Proposition}
\newtheorem{myclaim}{Claim}

\title{Randomness as Pointlessness}
\author{Greg Langmead}
\begin{document}
\maketitle
\section{Introduction}
Mathematicians have been exploring the advantages of locale theory for 60 or so years, along with its related disciplines of topos theory and type theory. When you tie one hand behind your back (such as avoiding the use of the existence of points, the axiom of choice, and/or the law of the excluded middle) then the constructions and proofs you invent can be more illuminating and deeper than before. I want to convince you that this may be true for algorithmic randomness notions. In \cite{simpson}, Alex Simpson has formulated a measure theory for locales and provided a new definition of randomness in this setting. I will describe this work, emphasizing the \emph{point-free} interpretation.

Random real numbers satisfy the following hand-waving characterizations.
\begin{enumerate}
\item They cannot be obtained constructively.
\item They obey almost-everywhere properties.
\item They appear tied to the foundations of mathematics.
\end{enumerate}
For a survey of these and other properties, see Rute \cite{rute}. I will argue that defining random points in terms of locales is well suited to capturing or even explaining all three of these properties. First of all, locales provide a setting for topology that supports constructive arguments, and randomness is in some sense the opposite of constructivity. Secondly, locales provide a model of topological spaces and continuous functions, so we can connect with classical results in analysis including almost-everywhere theorems like Lebesgue's theorem. And thirdly locales mediate a generalization from set theory to topos theory and type theory, modern constructive settings where mathematical foundations are being explored. Constructions like the effective topos and assemblies capture computability in this general context. It seems inevitable that randomness will find enhanced definitions in these new foundations.

\subsection{Randomness vs determinism: a confused debate}
In the Stanford Encyclopedia of Philosophy's article on Chance and Randomness \cite{sep-chance-randomness}, section 5.2 ("Chaotic Dynamics"), the authors describe an iterated transformation on the unit square, somewhat analogous to repeatedly folding dough. Given a starting point $(p,q), 0\leq p, q\leq 1$, define a function
\[
\phi(p,q) =
 \begin{cases}
 (2p, q/2), & \text{if } 0 \le p \le \frac{1}{2} \\
 (2p-1,(1+q)/2), & \text{if } \frac{1}{2} \le p \le 1
 \end{cases}
 \]
As the authors say, ``This corresponds to transforming the unit square to a rectangle twice as wide and half the height, chopping off the right half, and stacking it back on top to fill the unit square again.'' So, needlessly more violent than folding, but close. If we represent $p$ and $q$ in their binary expansion, we have \[ \phi (0.p_1 p_2\ldots, 0.q_1 q_2\ldots) = (0.p_2 p_3\ldots , 0.p_1 q_1 q_2\ldots).\]
In the article this example is intended to convey a paradox. On the one hand, the system is ergodic and behaves like a random process. Points will wander throughout the space without any pattern. But on the other hand the system is deterministic. The bit shift formula shows how it works: this is an engine that uses the next bit of the binary expansion to determine where the point moves next.

The resolution of the paradox, I believe, is to worry more about whether you can get your hands on $p$ and $q$ in the first place. Sure, once you have them, the machine behaves deterministically. But you can't have them! They require an infinite amount of information to specify, and to have one is to provide its entire future path through the process. The problem with the paradox is therefore in one of its assumptions. The process is deterministic, but the randomness is in the input data.

Indeed, the most important property of random numbers appears to be their infinite nature, which prevents us from ever having one fully specified for us, either in a machine, in our minds, or in our theories. They are not computable, and they are not constructible.

Confusingly, there are several different definitions of algorithmic randomness. In fact there is a whole family (or if you're in a teasing mood, a zoo) of them. They go by names such as Martin-LÃ¶f randomness, Schnorr randomness, weak-$n$-randomness, and computable randomness. They are not equivalent but they form a simple chain of inclusions, and smart people have worked out that the differences can be explained and parameterized by a family of choices that relate them. What I will present here is a consideration that is orthogonal to the flavor of randomness, namely the \emph{packaging} of the random numbers inside the reals. The main ingredient is a shift from \emph{set theory} to \emph{locale theory}. A locale is a generalization of a topological space, and I will argue that it is very well suited to a philosophical interpretation of randomness.

\section{Frames and Locales}

Locale theory is point-free topology. See Johnstone \cite{johnstone1983} for an accessible survey, or Chapter IX of Mac Lane and Moerdijk \cite{maclane} for a pleasantly breezy but more thorough introduction, or Johnstone \cite{sketches} chapter C1 for a detailed treatment. We can also call it \emph{synthetic} topology in that it takes open sets as basic, undefined objects, instead of defining them as collections of points. Instead it is points that will become a derived concept. Topological spaces with their actual open sets of actual points provide examples of locales, but there are more general ones as well. This will give us a new point of view on randomness.

A locale is a \emph{frame}. A frame is a partially ordered set (poset) with finite meets $\wedge$ and arbitrary joins $\vee$, with a maximal element $\top$ and minimal element $\bottom$, and where the infinite distributive law holds: $$x \wedge (\bigvee_i y_i)=\bigvee_i (x\wedge y_i).$$ This definition is clearly abstracted from the axioms for a topology: we are to imagine the elements of the poset are open sets of a generalized space. If we require only countable joins then it is called a $\sigma$-frame. The open sets of a topological space form a frame (or a $\sigma$-frame). A frame map is a function that preserves finite meets and arbitrary joins. A $\sigma$-frame map preserves countable joins. We collect this data into the category \Frm\ of frames and \sFrm\ of $\sigma$-frames.

A continuous map between topological spaces induces a frame map on the frames of open sets, but in the opposite direction because the \emph{inverse} image of an open is open. This motivates the definition of the category \Locale\ of locales to be simply $\op{\Frm}$ and $\slocale=\op{\sFrm}$. (Recall that the opposite of a category is a category with all the same objects and morphisms, but with the direction of all the morphism arrows reversed.) We can define a functor $L:\Topcat\to\Locale$ on objects by mapping a space $X$ to its frame of open sets $\o(X)$ (so on objects, $L=\o$), and on morphisms by mapping a function $f:X\to Y$ to the opposite arrow of the induced morphism on frames, so that's two inversions giving us an arrow $L(f):L(X)\to L(Y)$.

We'll use notation like $X, Y, \ldots$ to denote locales, and $\o(X), \o(Y), \ldots$ to denote frames of open sets.

\section{Points}

Consider the topological space $\star$ consisting of a single point. Its topology is just the poset $\{\bot \leq \top\}$ (the empty set and the whole space). To treat points as a derived concept, note that a point in a space $X$ is equivalent to a map $\mathrm{pt}:\star\to X$, which at the level of frames is a map $\o(X)\to\{\top, \bot\}$. The inverse image of $\top$ is the collection of all open sets that contain the point $\mathrm{pt}(\star)$. This forms what is known as a \emph{completely prime filter} in the frame, which is a collection $P$ of opens such that if $x\vee y\in P$ then $x\in P$ or $y\in P$. (This is analogous to a prime ideal, or the ideal generated by a prime number.) We can then move forward with locales and completely prime filters instead of spaces and points!

Note how compatible this is with a constructive point of view. To supply a point you must supply a function $\star\to X$. The points aren't given, you have to do work to produce one.

Given a locale $X$, the set of completely prime filters constitutes the \emph{spatial part} of $X$, and this set inherits a topology from the structure of $X$. Locale maps preserve prime filters so we obtain a set function between the spatial parts of the locales. We can package this as a functor $S:\Locale\to\Topcat$ which turns out to be right adjoint to $L$. If we go back and forth with $S\circ L$, starting from an honest topological space, then we get back an equivalent space with an equivalent topology so long as the original space is \emph{sober}, which is a definition that is almost circularly defined to meet this condition. Hausdorff spaces are sober. (The mathematicians who developed locale theory were very self-conscious about the names according to Peter Johnstone in \cite{johnstone2} and it shows --- they chose great names like ``sober.'') 

We won't make use of $S$, but it's important to know about it to have a global picture of how spaces are embedded in the larger category of locales.

\section{Sublocales}

Mathematicians have been careful to choose the correct notion of subspace in this context: the sublocale. There are three equivalent ways to define sublocales. Normally I'd expect two since we are bouncing between two opposite categories. But there is a super interesting third definition as well, and the interplay of all three sheds light on the application to randomness.

\subsection{Definition 1: Embedded subspaces}
To me the most intuitive definition is the one that lets us think of a sublocale as being like an \emph{embedded subspace}, i.e. a monomorphic map with the extra requirement that the subspace is embedded. In the category of topological spaces this means the domain is homeomorphic to its image. For example, for a map from $[0,1]$ into a space $X$ to be an embedding the curve must not self-intersect or do anything pathological. In categorical terms embeddings and sublocales are \emph{regular monomorphisms} and these have special factorization properties. You can maybe already tell that this is a less permissive notion of subspace than subspaces in \Topcat, where any old subset of a topological space (i.e. any monomorphism) can be equipped with the subspace topology and considered a subobject.

\subsection{Definition 2: Quotients of frames}
In the category of frames the arrows are reversed and so a sublocale is in fact a quotient frame, i.e. an equivalence relation. Intuitively, two open sets are equivalent if they agree on the sublocale. Precisely, a sublocale $=_Y$ is an equivalence relation that preserves finite meets and arbitrary joins:
\begin{align*}
U=_Y V\mathrm{\ and\ }U'=_Y V'&\quad\implies\quad U\wedge U'=_Y V\wedge V' \\
U_i=_Y V_i\mathrm{\ for\ all\ } i\geq 0&\quad\implies\quad \bigvee_{i\geq 0}U_i =_Y \bigvee_{i\geq 0} V_i.
\end{align*}

\subsection{Definition 3: Nuclei}
The nucleus definition of a sublocale also takes place in the category of frames. It is just the surjective map corresponding to the quotient. A nucleus is a function $j:\o(X)\to\o(X)$ satisfying
\begin{align*}
U&\leq jU \\
jjU &= jU \\
j(U\wedge V)&=j(U)\wedge j(V)
\end{align*}
The intuition is that $j$ takes an open set to some largest version of itself satisfying some property, which is why the first condition has the containment, and why the second condition is idempotence -- doing the operation twice yields the same largest open. The third condition is that forming the ``largest version'' preserves finite intersection.

Denote the fixed points of $j$ (i.e. the collection of largest sets) by $\o_j(X)$ and denote the dual object by $X_j$. Then $X_j$ is the sublocale. The map $j$ is a surjective frame map onto the set of fixed points, and so gives an embedding $i:X_j\hookrightarrow X$. This is basically performing the quotient from the previous definition, mapping every open onto the largest representative in the equivalence class.

\subsection{The collection of all sublocales}

The collection of all sublocales of a fixed locale $X$ is partially ordered by inclusion, just as we have in any category where we can define subobjects. It's worth mentioning that even more is true: the collection of sublocales forms a \emph{coframe}, which is duel to a frame, so is a poset with finite joins and arbitrary meets, and where the joins distribute over the meets. This collection is nowhere near as straightforward to contemplate as the collection of subsets of a set, but we will keep thinking through some of the consequences to find how it connects with randomness.

\subsection{A pointless sublocale}

We're ready to define a sublocale with no points! Let $X$ be a Hausdorff topological space without isolated points and let $\o(X)$ be the frame of its open sets. Consider the double-negation operation $\neg\neg:\o(X)\to\o(X)$. What does this do? The negation of an open $U$ is the largest open disjoint from $U$ (or equivalently, the union of all opens disjoint from $U$). In an actual space such as $X$ this is the same as the interior of the complement, but in a locale we don't have complements since they are not open. Repeating the operation, $\neg\neg U$ is thus the largest open disjoint from the largest open disjoint from $U$. For a lot of sets this is just $U$ again but sometimes it erases information. For any $p\in X$ we have that $\neg\neg(X-\{p\}) = X$, because $\neg (X-\{p\})=\emptyset$. So this operation blurs out the points.

$\neg\neg$ is idempotent, and in fact defines a nucleus hence an embedding $nn:X_{\neg\neg}\hookrightarrow X$, where $nn^{-1}U=\neg\neg U$. It's this sublocale $X_{\neg\neg}$ that has no points. For suppose $p:\star\to X_{\neg\neg}$ is a point. The composition $nn\circ p$ is thus a point of $X$. Consider the open set given by deleting this point from $X$, i.e. $X-\{nn(p(\star))\}$. Taking the inverse image in frames we have $p^{-1}(\neg\neg(X-\{nn(p(\star))\})) = \bot$ because only opens that contain the image of $\star$ map back to $\top$. But as we saw in the previous paragraph $\neg\neg(X-\{nn(p(\star))\}) = X$, so the above expression $p^{-1}(\neg\neg(X-\{nn(p(\star))\})$ becomes $p^{-1}(X)$ which is $\top$, a contradiction! You can't have points if you blurred away the points.

Furthermore, $X_{\neg\neg}$ is \emph{dense} in $X$. For a sublocale $A\hookrightarrow X$ to be dense means that $A$ intersects every open sublocale. (An open sublocale is one of the original open sets in $X$, promoted to a sublocale by embedding it in $X$.) This follows from being a nucleus: $\neg\neg A \supseteq A$. The definitions are piling up, aren't they?

\subsection{Locale morphisms}

A fact that makes the category of locales different from the category of spaces is that any two dense sublocales intersect to form another dense sublocale! If we intersect all dense sublocales we form a \emph{smallest dense sublocale} of any locale $X$ and it turns out to be exactly $X_{\neg\neg}$. By smallest I mean inside the poset of sublocales. None of this is the case with topological spaces such as $\mathbb{R}$ which can be decomposed into disjoint dense sub\emph{sets} such as $\mathbb{Q}$ and $\mathbb{R}\backslash\mathbb{Q}$. This is confusing! What does the sublocale $\mathbb{Q}\hookrightarrow\mathbb{R}$ look like then? The consequences for measure theory are significant, since defining measures on sets leads to some pathological examples involving cosets of the rationals.

Let's look at the \emph{image} of a sublocale inclusion. For this we need the ``push-forward'' map $f_*:\o(X)\to\o(Y)$, which is actually right adjoint to the inverse image map $f^{-1}:\o(Y)\to\o(X)$. It is defined as follows: $$f_*(U)=\bigcup_{f^{-1}(V)\subseteq U}V.$$ In other words, an open set $U\subseteq X$ maps under $f_*$ to the \emph{largest} open set in $Y$ that pulls back to some subset of $U$.

This is an elementary operation but not one that comes up in a standard undergraduate topology course (at least a 20th century one!). Here's an example that may help: imagine $f:[0,1]\to\mathbb{R}^2$ is some smooth curve in the plane. Given an open interval $(a,b)\subseteq[0,1]$, its image in the plane is a one-dimensional subset, so won't itself be open. Instead to compute $f_*((a,b))$ we have to find the largest open set in the plane whose inverse image is $(a,b)$, which will look like \emph{all of $\mathbb{R}^2$} minus two skinny pieces of the curve that are the images of $[0,a]$ and $[b,1]$. So it has the image in it, plus all the rest of the plane that isn't in the image of the rest of $[0,1]$.

The requirement that $f_*$ give the \emph{largest} open set such that some condition holds should remind us of a nucleus. In fact given a sublocale $f:X\to Y$ then $f_* \circ f^{-1}$ is the nucleus for the sublocale! It maps an open set to the direct image of its inverse image, which will be the largest open that contains the one you started with, and which itself also maps back to the same open in $X$.

Now let's get back to considering the inclusion $i:\mathbb{Q}\hookrightarrow\mathbb{R}$. The  push-forward map $i_*$ sends the open set ``all of $\mathbb{Q}$'' in $\mathbb{Q}$ to the largest open in $\mathbb{R}$ whose inverse image is contained in $\mathbb{Q}$. But $\mathbb{Q}$ is dense so this is all of $\mathbb{R}$! There's no smaller open that contains the rationals! The requirement that this push-forward be an open set is forbidding us from carving out these pathological dense subsets in the category of locales. The topological glue of the real numbers is constraining what kind of subobjects we have access to.

\section{Measure theory}

We have prepared all the abstract background. We have a new setting for topology called locale theory, which has broken away from the concept of a point. We have seen that the monomorphisms are different than in the category of topological spaces, and we have examples of sublocales that have no points. Let's bring measure theory into the mix and define randomness in this setting.

Technically we are back to requiring the ``\sig'' on the words ``frame'', ``locale'' and ``sublocale'' so that we can reconnect with the countability requirements of measures. On the other hand many spaces we care about are ``strongly LindelÃ¶f'' and we can drop the \sig. Simpson works out the details in \cite{simpson}. To be strongly LindelÃ¶f means that for any collection of open sets, their union is contained in a \emph{countable} union of open sets. This includes $\mathbb{R}$. For the rest of the essay we'll assume we are dealing with strongly LindelÃ¶f spaces and we'll drop the \sig, but of course the full theory can be more general if we want.

We will define a measure on a locale/frame and then extend it to all the sublocales of the frame.

A measure on a frame is a function $\mu:F\to [0,\infty]$ satisfying
$$\mu(\bot)=0$$
$$x\leq y\implies \mu(x)\leq\mu(y)$$
$$\mu(x)+\mu(y)=\mu(x\vee y)+\mu(x\wedge y)\quad\mathrm{("modularity")}$$
$$(x_i)_{i\geq 0}\mathrm{\ ascending\ }\implies \mu(\bigvee_{i\geq 0}x_i)=\sup_{i\geq 0}\mu(x_i)\quad\mathrm{("continuity")}.$$
We say $\mu$ is a probability measure if $\mu(\top)=1$. We will also call $\mu$ a measure on a locale if it is a measure on the corresponding frame of opens.

To bring the concept of measure to sublocales we will generalize the concept of outer measure. We say a locale is \emph{fitted} if for every sublocale $Y\subseteq X$ it holds that $Y=\bigwedge\mathcal{N}(Y)$ where $\mathcal{N}(Y)=\{U\in\o(X)|Y\subseteq U\}$, the family of opens containing $Y$. We extend the measure $\mu$ to a measure $\mu^*$ on any sublocale by $\mu^*(Y)=\inf_{U\in\mathcal{N}(Y)}\mu(U)$, i.e. the limit of the measure of the open sets that intersect to $Y$. There is work to show that spaces we care about are fitted, and that this definition really defines a measure (see section 5 of \cite{simpson}).

We can now cash in the fact that we cannot decompose locales into two dense sublocales. Simpson \cite{simpson} proves in Example 4.7 that the standard measure on open subsets of $\mathbb{R}^n$, which extends to a measure on sublocales in the way we just defined, is preserved under Euclidean translations. This measure agrees with Lebesgue measure whenever the sublocale agrees with a measurable set. In standard measure theory there is no translation invariant measure on arbitrary subsets of $\mathbb{R}^n$ due to pathological examples like cosets of rational numbers, which of course are automatically avoided in locale theory. 

\subsection{The random sublocale}
We are ready to define the random sublocale $\ran_X$ of an arbitrary locale $X$ equipped with a probability measure $\mu$. We'll do it three times, once for each definition of sublocale.

The spatial definition of $\ran_X$ is the smallest sublocale of measure 1, or equivalently the intersection of all sublocales of measure 1. This tracks exactly with the definition of Kurtz randomness seen in the algorithmic randomness literature. It's morally similar to $X_{\neg\neg}$ but making use of measure. $X_{\neg\neg}$ is the smallest dense sublocale of $X$, whereas $\ran_X$ is the smallest measure-1 sublocale.

The quotient definition of $\ran_X$ is the equivalence relation $=_{\ran_X}$ given by $U=_{\ran_X} V \iff \mu(U)=\mu(U\cap V)=\mu(V)$. Opens are equivalent if they cover the same piece of space with equal measure.

The nucleus definition is not mentioned by Simpson, but obviously it's given by $j_{\ran_X}(U) = \bigcup_{V\supseteq U, \mu(U)=\mu(V)}V.$ In other words, it maps $U$ to the maximal open that contains $U$ and has the same measure as $U$.

This sublocale has no points! Given a point $p\in X$, the set $X-\{p\}$ has measure 1 and so $\ran_X\subseteq X-\{p\}$ and so $p$ is not present in the random sublocale. Equating sets blurs away the points like $\neg\neg$ does.

\section{Conclusion: open sets vs randomness}
Topology is about open sets, and open sets correspond to semideciadable properties, i.e. properties that can be verified in finite time, but might need infinite time to refute. This is philosophically adjacent to being computable and constructive. In the Cantor space of binary sequences, the open sets are unions of cylinders, which are finite prefixes of sequences. We can verify propositions about infinite sequences just when we can do it in finite time. The finiteness is the openness and vice versa.

Locales take just the open sets from topology and build from there, without allowing us to have points unless we can construct them.

We've seen that locales behave very differently! There have smallest dense subsets so you can't decompose the reals into a disjoint union of rational and irrational. The topological glue constrains you from doing this.

Measure theory can be done on locales and it avoids some pathological problems that set theory causes. And we can form a smallest full-measure sublocale, ``random sublocale.'' This sublocale has no points.

So if we revisit our set theoretic foundations and consider open sets to be primary, then we arrive at a definition of randomness where the randoms constitute a space with full measure but no points. This makes perfect sense once you appreciate that having points requires work to produce one, but random points can never be fully produced.

This simple presentation gives the appearance, at least to me, that locale theory permits only one definition of randomness, which if true would be a major disadvantage. Algorithmic randomness contains a few moving parts such as whether certain measures can be computably obtained, or whether convergence of a limit is computable or can be computably bounded. Can we gain control over analogous parts of the theory within locale theory? Or are we stuck with Kurtz randomness? There are indications that the Borel hierarchy of sets can be imported into locale theory\footnote{See slides by Simpson at \url{https://ccc2017.loria.fr/slides/ccc_simpson.pdf}.} from which we could obtain weak $n$-randomness, so that would be the logical next step to flesh out.

Perhaps there is another option, which is that locale theory may not by itself offer control over all the extra choices contained in the theory of algorithmic randomness, but that passing from locales to the theory of assemblies in a realizability topos may offer them instead. Topos theory is built on top of locale theory, so this would be like continuing the narrative. In such a case locales would offer the unified big picture of the origins of randomness, which are then exported to different implementations.

Lastly let me speculate on the role of almost-everywhere properties in locale theory. I imagine we could replace statements like 
\begin{quote}
$x\in [0,1]$ is Schnorr random if and only if every computable function $f$ of bounded variation with effectively integrable derivative $f'$ is differentiable at $x$
\end{quote}
with 
\begin{quote}
If $f:[0,1]\to\mathbb{R}$ is a morphism in \Locale, then $f$ is differentiable on $\ran_{[0,1]}$.
\end{quote}

We could perhaps drop the explicit requirement of computability because we'd be in a constructive framework already, and instead of stating the result pointwise we'd have a global statement. It remains to properly define smoothness in the locale framework and to work out many details!

\begin{comment}
How Kurtz randomness fails the LLN (see \cite{NiesAndre2009CaR}, Section 3.5). 

Paper: locale theory
- Is the relationship between nucleus and quotient always just that each set gets mapped to its value under the nucleus? The nucleus map is the quotient map?
- Ran, the sublocale of random points
- presumably we can say some class of functions are smooth on this sublocale?
- Porter provides some justification for the locale approach since it's "all measure 1 properties"
- are there countable bounds on the collections, in the locale theory?
- given some notion of randomness, the interval [0,1] can be given the corresponding locale structure
- does this mean that each notion of randomness has its own topology? or are the topologies the same just with different numbers of points, and different Ran? (must be a different topology, right? because once you have a point you have an ideal of open sets, else not)
- what corresponds to the different amounts of computability and/or martingale bounds?
- will the punch line be that the locale approach is agnostic to which definition of randomness we work with, but simply takes any of the notions and removes random points from the space?
- how does the existence of a universal ML test play out in locales?
- the a.e. results like "if f is nondecreasing then it is smooth at every computable random" feel like statements about cohesion, and this feels natural in the locale interpretation
- she is saying that Birkhoff Ergodicity theorem, suitably effectivized, holds at ML randoms, i.e. the same set that functions of bounded variation are smooth at -- making them "equally strong". But in another sense these are different topologies on R and so we can also say that given this topology these are the classes of functions.
- Church's thesis that there are no non-computable reals -- has a natural home here.
\end{comment}
\bibliographystyle{unsrt}
\bibliography{locales}
\end{document}
