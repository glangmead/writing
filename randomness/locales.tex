\documentclass[14pt]{extarticle}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{tikz-cd}
\usepackage{tipa}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}

%\usepackage{mathptmx}

%\usepackage[osf,slantedGreek]{mathpazo}
%\usepackage{newtxtext}
%\usepackage{newtxmath}
%
% uncomment the four lines below to switch to stix times
%\usepackage{stix} % when using stix, \circ doesn't have binary operator spacing, so fix that
%\let\mycirc\circ
%\renewcommand{\circ}{\mathbin{\mycirc}}
%\newcommand{\bracket}[2]{\left\<#1,#2\right\>}
%\newtheorem{claim}{Claim}


%%% Common categories
\newcommand{\tp}{\;\mathrm{type}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\G}{\Gamma}
\newcommand{\pit}[1]{\prod_{(#1)}} % pi-type
\newcommand{\pitxa}{\pit{x:A}}
\newcommand{\sit}[1]{\sum_{(#1)}} % sigma-type
\newcommand{\ent}{\vdash}
\newcommand{\adj}{\dashv}
\newcommand{\refl}{\ensuremath{\textsf{refl}}}
\newcommand{\ap}{\ensuremath{\textsf{ap}}}
\newcommand{\ind}{\ensuremath{\textsf{ind}}}
\newcommand{\lift}{\ensuremath{\textsf{lift}}}
\newcommand{\inv}{\ensuremath{\textsf{inv}}}
\newcommand{\concat}{\ensuremath{\textsf{concat}}}
\newcommand{\transport}{\ensuremath{\textsf{transport}}}
\renewcommand{\sec}{\ensuremath{\textsf{sec}}}
\newcommand{\retr}{\ensuremath{\textsf{retr}}}
\newcommand{\total}{\ensuremath{\textsf{total}}}
\newcommand{\isequiv}{\ensuremath{\textsf{is\_equiv}}}
\newcommand{\fib}{\ensuremath{\textsf{fib}}}
\newcommand{\id}{\ensuremath{\text{id}}}
\newcommand{\judgeq}{\ensuremath{:\equiv}}
\newcommand{\reflfx}{\ensuremath{\refl_{f(x)}}}

\newcommand{\rr}{\ensuremath{\mathbb{R}}}
\newcommand{\rrn}{\ensuremath{\mathbb{R}^n}}
\newcommand{\rrm}{\ensuremath{\mathbb{R}^m}}
\newcommand{\rrx}{\ensuremath{\mathbb{R}[x]/x^2}}
\newcommand{\rry}{\ensuremath{\mathbb{R}[y]/y^2}}
\newcommand{\cc}{\ensuremath{\mathbb{C}}}
\newcommand{\nn}{\ensuremath{\mathbb{N}}}
\newcommand{\dd}{\ensuremath{\mathbb{D}}}
%\newcommand{\vv}{\ensuremath{\mathbb{V}}}
\newcommand{\cinfty}{\ensuremath{C^{\infty}}}
\newcommand{\smfd}{\textsf{SmoothMfd}}
\newcommand{\calg}{\textsf{CAlg}_{\rr}}
\newcommand{\cart}{\textsf{CartSp}}
\newcommand{\formalcart}{\textsf{FormalCartSp}}
\newcommand{\formalsmoothset}{\textsf{FormalSmoothSet}}
\newcommand{\smoothset}{\textsf{SmoothSet}}
\newcommand{\setcat}{\textsf{Set}}
\newcommand{\psh}[1]{\textsf{Psh}(#1)}
\newcommand{\sh}[1]{\textsf{Sh}(#1)}
\newcommand{\pshcart}{\psh{\cart}}
\newcommand{\rmodal}{\Re}
\newcommand{\imodal}{\Im}
\newcommand{\shape}{\ensuremath{\text{\textesh}}}
\newcommand{\op}[1]{#1^{\textsf{op}}}
\newcommand{\pt}{\mathrm{pt}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\BAut}{\mathrm{BAut}}
\newcommand{\im}{\mathrm{im}}
\newcommand{\Fin}{\mathrm{Fin}}
\newcommand{\Type}{\mathrm{Type}}
\newcommand{\bottom}{\ensuremath{\bot}}
\newcommand{\Frm}{\ensuremath{\mathsf{Frm}}}
\newcommand{\sFrm}{\ensuremath{\mathsf{\sigma Frm}}}
\newcommand{\Locale}{\ensuremath{\mathsf{Loc}}}
\newcommand{\Topcat}{\ensuremath{\mathsf{Top}}}
\newcommand{\slocale}{\ensuremath{\mathsf{\sigma Loc}}}
\newcommand{\opens}[1]{\ensuremath{\mathcal{O}(#1)}}
\renewcommand{\o}{\ensuremath{\mathcal{O}}}

\newcommand{\bg}{\ensuremath{\textbf{B}G}}
\newcommand{\bgconn}{\ensuremath{\textbf{B}G_{\textsf{conn}}}}
\newcommand{\bgdiff}{\ensuremath{\textbf{B}G_{\textsf{diff}}}}
\newcommand{\ran}{\ensuremath{\mathrm{Ran}}}

\newcommand{\gc}[1]{\marginpar{\bf $\leftarrow$ {#1}}}
%\newcommand{\gc}[1]{}
\newcommand{\commentout}[1]{}

\newtheorem{mydef}{Definition}
\newtheorem{mythm}{Theorem}
\newtheorem{mylemma}{Lemma}
\newtheorem{myprop}{Proposition}
\newtheorem{myclaim}{Claim}

\title{Randomness as Pointlessness}
\author{Greg Langmead}
\begin{document}
\maketitle
\section{Introduction}
Random real numbers satisfy the following hand-waving characterizations.
\begin{enumerate}
\item They cannot be obtained constructively.
\item They obey almost-everywhere properties quantified over classes of functions.
\item They appear tied to the foundations of mathematics.
\end{enumerate}
For a survey of these and other properties, see Rute \cite{rute}. I will argue that defining random points in terms of locales is well suited to capturing or even explaining all three of these properties.
\section{Randomness vs determinism: a confused debate}
In the Stanford Encyclopedia of Philosophy's article on Chance and Randomness \cite{sep-chance-randomness}, section 5.2 ("Chaotic Dynamics"), the authors describe an iterated transformation on the unit square, somewhat analogous to repeatedly folding dough. Given a starting point $(p,q), 0\leq p, q\leq 1$, define a function
\[
\phi(p,q) =
 \begin{cases}
 (2p, q/2), & \text{if } 0 \le p \le \frac{1}{2} \\
 (2p-1,(1+q)/2), & \text{if } \frac{1}{2} \le p \le 1
 \end{cases}
 \]
As the authors say, ``This corresponds to transforming the unit square to a rectangle twice as wide and half the height, chopping off the right half, and stacking it back on top to fill the unit square again.'' So, needlessly more violent than folding, but close. If we represent $p$ and $q$ in their binary expansion, we have \[ \phi (0.p_1 p_2\ldots, 0.q_1 q_2\ldots) = (0.p_2 p_3\ldots , 0.p_1 q_1 q_2\ldots).\]
In the article this example is intended to convey a paradox. On the one hand, the system is ergodic and behaves like a random process. Points will wander throughout the space without any pattern. But on the other hand the system is deterministic. The bit shift formula shows how it works: this is an engine that uses the next bit of the binary expansion to determine where the point moves next.

The resolution of the paradox, I believe, is to worry more about whether you can get your hands on $p$ and $q$ in the first place. Sure, once you have them, the machine behaves deterministically. But you can't have them! They require an infinite amount of information to specify, so if you have them you have just recapitulated the future history of the machine. The problem with the paradox is therefore in one of its assumptions. The process is deterministic, but the randomness is in the input data.

Indeed, the most important property of random numbers appears to be their infinite nature, which prevents us from ever having one fully specified for us, either in a machine, in our minds, or in our theories. They are not computable, and they are not constructible.

However, there are several different definitions of algorithmic randomness. In fact there is a whole family (or if you're in a teasing mood, a zoo) of them. They go by names such as Martin-LÃ¶f randomness, Schnorr randomness, weak-$n$-randomness, and computable randomness. They are not equivalent but they form a simple chain of inclusions, and the differences can be logically explained and outsourced to a family of choices or parameters that connect them. What I will present here is a consideration that is orthogonal to the flavor of randomness, and this is the \emph{packaging} of the random numbers inside the reals. The main ingredient is a shift from \emph{set theory} to \emph{locale theory}. A locale is a generalization of a topological space, and I will argue that it is very well suited to a philosophical interpretation of randomness.

In \cite{simpson}, Alex Simpson has formulated a measure theory for locales and provided a new definition of randomness in this setting. We will describe this work, emphasizing the \emph{point-free} interpretation. The beautiful punch line will be that the sublocale of randoms has no points! This is a wonderful result that feels tailor-made for discussing randomness. Locales are a generalization of spaces with just  where we can define continuity, computability (after passing to toposes of sheaves, which naturally live over locales). 

The beauty of the locale formulation of measure theory is that it can construct an environment for discussing randomness that highlights the inability to access individual random numbers. It does this because it \emph{restricts} us from constructing certain measurable sets?? We will adopt the point of view of \emph{pointless topology}. In a locale, we frame our theory not in terms of the points of a set, but in terms of the open subsets of a space. It is then extra data to produce a point of a locale. The central result of this paper is that the random sub-locale of a locale has no points.

\section{Frames and Locales}

Locale theory is point-free topology. See \cite{johnstone1983} for an accessible survey, or Chapter IX of Mac Lane and Moerdijk \cite{maclane} for a pleasantly breezy but more thorough introduction. It is \emph{synthetic} in that it takes open sets as basic, undefined objects, instead of defining them as collections of points. Instead it is points that will become derived. Topological spaces with their actual open sets of actual points are special cases of locales, but the enlarged category of locales has a few advantages. First of all it lets us argue constructively. Secondly it isolates just the axioms we need to prove many theorems from topology. Thirdly it will give us a unique point of view on randomness.

A \emph{frame} is a partially ordered set with finite meets $\wedge$ and arbitrary joins $\vee$, with a maximal element $\top$ and minimal element $\bottom$, and where the infinite distributive law holds: $$x \wedge (\bigvee_i y_i)=\bigvee_i (x\wedge y_i).$$ These are clearly snagged from the axioms for a topology. If there are only countable joins then it is called a $\sigma$-frame. The open sets of a topological space form a frame. A frame map is a function that preserves finite meets and arbitrary joins. A $\sigma$-frame map preserves countable joins. We collect this data into the category \Frm\ of frames and \sFrm\ of $\sigma$-frames.

A continuous map between topological spaces induces a frame map on the frames of open sets, but in the opposite direction because the \emph{inverse} image of an open is open. This motivates the definition of the category \Locale\ of locales to be simply $\op{\Frm}$ and $\slocale=\op{\sFrm}$. (Recall that the opposite of a category is a category with all the same objects and morphisms, but with the direction of all the morphism arrows reversed.) We can define a functor $\o:\Topcat\to\Locale$ on objects by mapping a space $X$ to its frame of open sets $\o(X)$, and on morphisms by mapping a function $f:X\to Y$ to the opposite arrow of the induced morphism on frames, so that's two inversions giving us an arrow $\o(f):\o(X)\to \o(Y)$. This functor has an important right adjoint which we will discuss next.

For the topological space $\star$ consisting of a single point, its topology is just $\{\bot \leq \top\}$. To convert points into a derived concept then, we can note that a point in a space $X$ is equivalent to a map $\mathrm{pt}:\star\to X$, which at the level of frames is a map $\o(X)\to\{\top, \bot\}$. The inverse image of $\top$ is the collection of all open sets that contain the point $\mathrm{pt}(\star)$. It forms what is known as a \emph{completely prime filter} in the frame, which is a collection $P$ of opens such that if $x\vee y\in P$ then $x\in P$ or $y\in P$. (This is analogous to a prime ideal, or the ideal generated by a prime number.) We can then move forward with locales and completely prime filters instead of spaces and points. 

Given a locale $L$, the set of completely prime filters constitutes the \emph{spatial part} of $L$, and this set inherits a topology from the structure of $L$. Locale maps create an association between the completely prime filters, and so we obtain a set function between the spatial parts of the locales. This is a functor $S:\Locale\to\Topcat$ and is right adjoint to $\o$. If we go back and forth with $S\circ \o$, starting from an honest topological space, then we get back an equivalent space with an equivalent topology so long as the original space is \emph{sober}, which is a definition that was new to me, but is almost circularly defined to meet this condition. Hausdorff spaces are sober. This is the categorical situation whereby locales are generalized spaces, and being spatial, and having points, are derived special properties.

Note how compatible this is with a constructive point of view. To supply a point you must supply a function $\star\to X$. The points aren't given, you have to do work to produce one.

So given an arbitrary locale, it may or may not have points. And given some underlying set such as the real interval $[0,1]$, there may be a locale structure other than the standard topology, and this locale structure may have fewer points than the set $[0,1]$! To give a hint of how this may work, imagine deleting some of the open sets, so that the prime filters are not complete anymore. That's the approach we will take when we define certain \emph{sublocales}.

\section{Sublocales}

There are three equivalent ways to define sublocales. Normally I'd expect two since we are bouncing between two opposite categories. But there is a super interesting third definition as well, and the interplay of all three sheds light on the application to randomness.

\subsection{Definition 1: Embedded subspaces}
To me the most intuitive definition is the one that lets one think of a sublocale as an \emph{embedded subspace}, i.e. a monomorphic map with the extra requirement that the subspace is embedded. In the category of topological spaces and other concrete categories this means the domain is homeomorphic to its image. For example, for a map from $[0,1]$ into a space $X$ to be an embedding the curve must not self-intersect or do anything pathological. In categorical terms the sublocales are \emph{regular monomorphisms}. 

\subsection{Definition 2: Quotients of frames}
In the category of frames the arrows are reversed and so a sublocale is in fact a quotient, i.e. an equivalence relation. Intuitively, two open sets are equivalent if they agree on the sublocale. In more detail, a sublocale $=_Y$ is an equivalence relation that preserves finite meets and arbitrary joins:
\begin{align}
U=_Y V\mathrm{\ and\ }U'=_Y V'&\quad\implies\quad U\cap U'=_Y V\cap V' \\
U_i=_Y V_i\mathrm{\ for\ all\ } i\geq 0&\quad\implies\quad \bigcup_{i\geq 0}U_i =_Y \bigcup{i\geq } V_i.
\end{align}

\subsection{Definition 3: Nuclei}
The nucleus definition of a sublocale also takes place in the category of frames. A nucleus is a function $j:\o(X)\to\o(X)$ satisfying
\begin{align}
U&\leq jU \\
jjU &= jU \\
j(U\wedge V)&=j(U)\wedge j(V)
\end{align}
The intuition is that $j$ takes an open set to some largest version of itself satisfying some property, which is why the first condition has the containment, and why the second condition is idempotence -- doing the operation twice yields the same largest open. The third condition is that forming the ``largest version'' preserves finite intersection.

Denote the fixed points of $j$ by $\o_j(X)$ and the dual object, i.e. its locale, by $X_j$. The map $j$ is a surjective frame map onto the set of fixed points, and so gives an embedding $i:X_j\hookrightarrow X$.

\subsection{Warmup example: a sublocale with no points}
Here's something that warrants some reflection: let's define a sublocale with no points. Let $X$ be a Hausdorff topological space without isolated points and let $\o(X)$ be the locale of its open sets. Consider the double-negation operation $\neg\neg:\o(X)\to\o(X)$. This defines a nucleus hence an embedding $nn:X_{\neg\neg}\hookrightarrow X$.

This sublocale $\neg\neg X$ has no points! For suppose $p:\star\to X_{\neg\neg}$ is a point. The composition $nn\circ p$ is a point of $X$ itself. Consider the open set given by deleting this point from $X$, i.e. $X-\{nn(p(\star))\}$. Mapping this open set backwards to $X_{\neg\neg}$ and then to $\star$, we have that $p^{-1}(\neg\neg(X-\{nn(p(\star))\}) = \bot$. It equals $\bot$ because only opens that contain the image of $\star$ give $\top$. But $X$ has no isolated points and so $\neg\neg(X-\{nn(p(\star))\} = X$, so the above expression $p^{-1}(\neg\neg(X-\{nn(p(\star))\})$ becomes $p^{-1}(X)$ which is $\top$, a contradiction.

\section{$\sigma$-versions}

\section{Measures thereon}
The collection of all sublocales of a fixed locale $X$ are ordered by inclusion and form a frame of their own which we denote by $\mathcal{S}(X)$. This is one level up so to speak, since $X$ itself is (the opposite of) a frame of open sets, and the sublocales are formed from the whole of this frame by way of a quotient operation.

We will define a measure on a locale/frame and then extend it to the frame of sublocales of the frame.

A measure on a frame is a function $\mu:F\to [0,\infty]$ satisfying
$$\mu(\bot)=0$$
$$x\leq y\implies \mu(x)\leq\mu(y)$$
$$\mu(x)+\mu(y)=\mu(x\vee y)+\mu(x\wedge y)\quad\mathrm{("modularity")}$$
$$(x_i)_{i\geq 0}\mathrm{\ ascending\ }\implies \mu(\bigvee_{i\geq 0}x_i)=\sup_{i\geq 0}\mu(x_i)\quad\mathrm{("continuity")}.$$
We say $\mu$ is a probability measure if $\mu(\top)=1$. We will also call $\mu$ a measure on a locale if it is a measure on the corresponding frame of opens.

To bring the concept of measure to sublocales we will generalize the concept of outer measure. We say a locale is \emph{fitted} if for every sublocale $Y\subseteq X$ it holds that $Y=\cap\mathcal{N}(Y)$ where $\mathcal{N}(Y)=\{U\in\o(X)|Y\subseteq U\}$. We extend the measure $\mu$ to a measure $\mu^*$ on any sublocale by $\mu^*(Y)=\inf_{U\in\mathcal{N}(Y)}\mu(U)$, i.e. the limit of the measure of the open sets that intersect to $Y$. There is work to show that spaces we care about are fitted, and that this definition really defines a measure (see section 5 of \cite{simpson}), but I will skip all that.

\section{The random sublocale}
We are ready to define the random sublocale $\ran_X$ of an arbitrary locale $X$ equipped with a probability measure $\mu$. We'll do it three times, once for each definition of sublocale.

The spatial definition of $\ran_X$ is the largest sublocale of measure 1, or equivalently the union of all sublocales of measure 1. This tracks exactly with the definition of Kurtz randomness seen elsewhere in the literature.

The quotient definition of $\ran_X$ is the equivalence relation $=_{\ran_X}$ given by $U=_{\ran_X} V \iff \mu(U)=\mu(U\cap V)=\mu(V)$. Opens are equivalent if they cover the same amount of measure.

The nucleus definition is that $j_{\ran_X}(U) = \bigcup_{V\supseteq U, \mu(U)=\mu(V)}V.$ In other words, the maximal open that contains $U$ and with the same measure as $U$. This is my educated guess, I haven't seen this in Simpson's writings or elsewhere as of yet. \gc{So prove it, wimp.}

This sublocale has no points.

\section{Kurtz randoms are not so bad}
How Kurtz randomness fails the LLN (see \cite{NiesAndre2009CaR}, Section 3.5). 

The prospect for importing all the various randomness notions into this framework. The $\mathcal{S}$ functor.

\section{But actually we can have the other kinds of randoms in locales too}
This doesn't appear to be thought through carefully yet in published work but it appears in sketch form in slides by Simpson \cite{simpson2}. He defines the Borel hierarchy in the context of locales, giving him definitions for $\Sigma^0_n$ and $\Pi^0_n$. Using these you can proceed with the definition of pointless sublocales of randoms. If every definition of randomness can be imported into this setting then we have a clean story where locales are a lens through which to look at the entire landscape of computable randomness. If, however, there are limitations to what can be expressed in locale theory, then the picture will get cloudy, but perhaps being compatible with locale theory can join the other popular metrics when assessing the tradeoffs between members of the randomness family.

\begin{commentout}
Paper: locale theory
- Ran, the sublocale of random points
- presumably we can say some class of functions are smooth on this sublocale?
- Porter provides some justification for the locale approach since it's "all measure 1 properties"
- are there countable bounds on the collections, in the locale theory?
- given some notion of randomness, the interval [0,1] can be given the corresponding locale structure
- does this mean that each notion of randomness has its own topology? or are the topologies the same just with different numbers of points, and different Ran? (must be a different topology, right? because once you have a point you have an ideal of open sets, else not)
- what corresponds to the different amounts of computability and/or martingale bounds?
- will the punch line be that the locale approach is agnostic to which definition of randomness we work with, but simply takes any of the notions and removes random points from the space?
- how does the existence of a universal ML test play out in locales?
- the a.e. results like "if f is nondecreasing then it is smooth at every computable random" feel like statements about cohesion, and this feels natural in the locale interpretation
- she is saying that Birkhoff Ergodicity theorem, suitably effectivized, holds at ML randoms, i.e. the same set that functions of bounded variation are smooth at -- making them "equally strong". But in another sense these are different topologies on R and so we can also say that given this topology these are the classes of functions.
- Church's thesis that there are no non-computable reals -- has a natural home here.
\end{commentout}
\bibliographystyle{unsrt}
\bibliography{locales}
\end{document}
